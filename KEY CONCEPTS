1. 机器学习（machine learning）：研究如何通过计算的手段，利用“经验”改善系统自身的性能。
  · 机器学习是一门“学科”
  · 机器学习是基于“经验”做出判断

2. “经验”：在计算机中以“数据”形式存在
  · 机器学习研究在计算机上从数据中产生“模型”（model）的算法，即“学习算法”（learning algorithm）
  · 机器学习是研究关于“学习算法”的学问
  · 经机器学习得到学习算法，把经验数据提供它，即可基于这些数据产生模型
  · 在面对新情况（输入新数据），模型会给出我们提供相应的判断
  
3. 模型（model）：泛指从数据中学得的结果
  · 有的文献，“模型”指全局性结果（例如一颗决策树），“模式”指局部性结果（例如一条规则） 
  
4. 数据
  · 数据集（data set）：记录的集合（有时将整个数据集称为一个“样本”，因它可看作对样本空间的一个采样）
  · 示例（instance）/ 样本（sample）：关于一个事件或对象的描述的每条记录
  · 属性（attribute）/ 特征（feature）：反映事件或对象在某方面的表现或性质的事项
  · 属性值（attribute value）：属性上的取值
  · 属性空间（attribute space）/ 样本空间（sample space）/ 输入空间：属性张成的空间。由于空间中的每个点对应一个坐标向量，任意示例亦可称为属性空间内的特征向量（feature vector）

例：一批关于西瓜的数据：
   （色泽=青绿；根蒂=蜷缩；敲声=浊响）、（色泽=乌黑；根蒂=稍蜷；敲声=沉闷）、（色泽=浅白；根蒂=硬挺；敲声=清脆）……每对括号内是一条记录，“=”即“取值为”
   · 这些记录的集合——数据集
   · 每条记录——示例/样本
   · “色泽”、“根蒂”、“敲声”——属性
   · “青绿”、“乌黑”——属性值
   · “色泽”、“根蒂”、“敲声”作为三个坐标值，则它们张成一个用于描述西瓜的三维空间，每个西瓜都可以在这个空间中找到自己的坐标位置
   
 数字化表示：
   · D={x1,x2,……,xm}包含m个示例的数据集
   · xi={xi1;xi2;……;xid}每个示例由d个属性描述,每个示例xi是d维样本空间X中的一个向量,xi∈X，xij是xi的第j个属性上的取值，d是样本xi的“维数”（dimensionality）

5. 学习（learning）/ 训练（training）：从数据中学得模型的过程，该过程是通过执行某个学习算法来完成的
   · 训练数据（training data）：训练过程中使用的数据，其中每个样本称为一个“训练样本”（training sample）
   · 训练集（training set）：训练样本组成的集合
   · 假设（typothesis）：训练学得的模型对应了关于数据的某种潜在的规律
   · 真相/真实（ground-truth）：潜在规律自身
   · 学习器（learn）：学习过程就是为了找出或逼近真相，故模型可称为学习器，可看作学习算法在给定数据和参数空间上的实例化
   注：学习算法通常有参数需要设置，使用不同的参数值和（或）训练数据，将产生不同的结果
   
6. 训练样本的“结果”信息：
例：（（色泽=青绿；根蒂=蜷曲；敲声=浊响），好瓜）
   · 标记（label）：关于示例结果的信息——“好瓜”
   · 样例（example）：拥有标记信息的示例（若将标记看作对象本身的一部分，则“样例”也可称为“样本”）
   · 标记空间（label space）/输出空间：所有标记的集合
     eg：(xi,yi)表示第i个样例，其中yi∈Y是示例xi的标记，Y是所有标记的集合——标记空间/输出空间
   
7. 预测任务：
   · 分类（classification）：预测的是离散值，如“好瓜”、“坏瓜”
   · 回归（regression）：预测的是连续值，如西瓜成熟度0.95、0.37
   · 二分类（binary classification）任务：只涉及两个类别的分类任务，通常其中一个类为“正类”（positive class），另一个为“反类/负类”（negative class）
     eg：对训练集{(x1,y1),(x2,y2),...,(xm,ym)}进行学习以完成预测任务，需建立一个从输入空间X到输出空间K的映射 f：X → Y
   · 二分类任务，通常Y={-1，+1}或{0,1}
   · 多分类（multi-class classification）任务：涉及多个类别
     eg：[续]多分类任务：|Y|>2;回归任务：Y=R，实数集
   
8. 测试（testing）:学得模型后，使用其进行预测的过程
   测试样本（testing sample）：被预测的样本
   eg：学得f后，对测试例x，可得到其预测标记y=f(x)
   
9. 聚类（clustering）：将训练集中的示例分成若干组，每组称为一个“簇”（cluster）
   自动形成的簇可能对应一些潜在的概念划分，这样的学习过程有助于我们了解数据内在的规律，能为更深入地分析数据建立基础。
   学习过程中使用的训练样本是通常不拥有标记信息。
   eg：对西瓜数据集进行聚类学习，可能对应潜在概念划分：“浅色瓜”、“深色瓜”或“本地瓜”、“外地瓜”且这些概念我们事先不知道，即不拥有标记信息
   
10. 学习任务分类：
    根据训练集是否拥有标记信息，学习任务可大致分为两类 —— 监督学习（supervised learning），如回归/无监督学习（unsupervised learning），如聚类

11.机器学习的目标：
   · 泛化（generalization）能力：学得模型适用于新样本的能力。
     · 机器学习的目标是使学得的模型能很好地适用于“新样本”，而不仅是在训练样本上工作得好
     · 具有强泛化的模型能很好地适用于整个样本空间
   · 分布（distribution）D：假设样本空间中全体样本服从一个未知“分布”（distribution）D，我们获得的样本都是独立地从这个分布上采样获得的，即“独立同分布”（independent and identically）
     · 一般，训练样本越多，我们得到的关于D的信息越多，这样就有可能获得具有强泛化能力的模型
     
   
   
  

   
